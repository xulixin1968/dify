model: Meta-Llama-3.1-405B-Instruct
label:
  en_US: Meta-Llama-3.1-405B-Instruct
model_type: llm
features:
  - agent-thought
model_properties:
  mode: chat
  context_size: 16000
parameter_rules:
  - name: temperature
    use_template: temperature
  - name: top_p
    use_template: top_p
  - name: top_k
    label:
      en_US: Top k
    type: int
    help:
      en_US: Only sample from the top K options for each subsequent token.
    required: false
  - name: max_tokens_to_sample
    use_template: max_tokens
    default: 4096
    min: 1
    max: 16000
pricing:
  input: '0.000005'
  output: '0.000010'
  unit: '1'
  currency: USD
